"""
LangGraphå·¥ä½œæµé›†æˆæ¨¡å—
ç›´æ¥è°ƒç”¨ç°æœ‰çš„LangGraphæ•°æ®åˆ†æå·¥ä½œæµ
"""

import asyncio
import json
import uuid
import sys
from datetime import datetime
from typing import Dict, Any, Optional, Generator, List, AsyncGenerator
from pathlib import Path
import pandas as pd

import streamlit as st

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.append(str(project_root))

# å¯¼å…¥ç°æœ‰çš„LangGraphå·¥ä½œæµ
try:
    from main_workflow import create_main_workflow, MainWorkflowState
    from langgraph.checkpoint.memory import MemorySaver
    LANGGRAPH_AVAILABLE = True
except ImportError as e:
    print(f"Warning: LangGraph modules not available: {e}")
    LANGGRAPH_AVAILABLE = False

# å…¨å±€å…±äº«çš„checkpointerå®ä¾‹ï¼Œç¡®ä¿åœ¨æ•´ä¸ªStreamlitä¼šè¯ä¸­æŒä¹…åŒ–
_GLOBAL_CHECKPOINTER = None

def get_global_checkpointer():
    """è·å–å…¨å±€å…±äº«çš„checkpointerå®ä¾‹"""
    global _GLOBAL_CHECKPOINTER
    if _GLOBAL_CHECKPOINTER is None:
        _GLOBAL_CHECKPOINTER = MemorySaver()
        print("åˆ›å»ºæ–°çš„å…¨å±€ MemorySaver å®ä¾‹")
    return _GLOBAL_CHECKPOINTER

class LangGraphIntegration:
    """LangGraphå·¥ä½œæµé›†æˆç±»"""

    def __init__(self):
        self.graph = None
        self.compiled_graph = None
        self.pending_workflows = {}  # å­˜å‚¨ç­‰å¾…äººå·¥å®¡æŸ¥çš„å·¥ä½œæµçŠ¶æ€
        self.initialize_workflow()

    def initialize_workflow(self) -> bool:
        """åˆå§‹åŒ–LangGraphå·¥ä½œæµ"""
        try:
            if not LANGGRAPH_AVAILABLE:
                st.error("LangGraphå·¥ä½œæµæ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥é¡¹ç›®ç»“æ„")
                return False

            # è®¾ç½®å…¨å±€å…±äº«çš„checkpointer
            global_checkpointer = get_global_checkpointer()

            # å¯¼å…¥main_workflowæ¨¡å—å¹¶è®¾ç½®å¤–éƒ¨checkpointer
            import main_workflow
            main_workflow.set_external_checkpointer(global_checkpointer)

            # å¼ºåˆ¶è®¾ç½®webuiç¯å¢ƒå˜é‡ï¼Œç¡®ä¿ä½¿ç”¨checkpointer
            import os
            # åœ¨webuiç¯å¢ƒä¸‹ï¼Œæˆ‘ä»¬éœ€è¦checkpointeræ¥æ”¯æŒinterrupts
            original_env = os.getenv("LANGGRAPH_API_ENV")
            os.environ["LANGGRAPH_API_ENV"] = "false"  # å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°checkpointer

            try:
                # åˆ›å»ºå¹¶è·å–å·²ç¼–è¯‘çš„å·¥ä½œæµå›¾
                self.compiled_graph = create_main_workflow()
                self.graph = self.compiled_graph  # ä¿æŒå‘åå…¼å®¹
                print(f"æˆåŠŸåˆå§‹åŒ–å·¥ä½œæµï¼Œä½¿ç”¨å…±äº«checkpointer: {type(global_checkpointer)}")
            finally:
                # æ¢å¤åŸæ¥çš„ç¯å¢ƒå˜é‡
                if original_env is not None:
                    os.environ["LANGGRAPH_API_ENV"] = original_env
                else:
                    os.environ.pop("LANGGRAPH_API_ENV", None)

            st.session_state.langgraph_connected = True
            return True

        except Exception as e:
            st.error(f"LangGraphåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            st.session_state.langgraph_connected = False
            self.compiled_graph = None
            return False

    async def process_query_async(
        self,
        user_question: str,
        session_id: str = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å¼‚æ­¥å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        ä½¿ç”¨Generatorå®ç°æµå¼å“åº”
        """

        if not self.compiled_graph:
            yield {
                "type": "error",
                "content": "LangGraphå·¥ä½œæµæœªåˆå§‹åŒ–",
                "step": "initialization"
            }
            return

        try:
            # æ„å»ºè¾“å…¥çŠ¶æ€
            workflow_input = MainWorkflowState(
                user_question=user_question,
                session_id=session_id or f"session_{uuid.uuid4()}"
            )

            yield {
                "type": "workflow_start",
                "content": "å¼€å§‹åˆ†æé—®é¢˜",
                "step": "start",
                "title": "ğŸš€ å·¥ä½œæµå¯åŠ¨"
            }

            # æ‰§è¡Œå·¥ä½œæµå¹¶æµå¼è¿”å›ç»“æœ
            async for event in self.compiled_graph.astream(workflow_input):
                node_name = list(event.keys())[0]
                node_output = event[node_name]

                # è½¬æ¢å·¥ä½œæµäº‹ä»¶ä¸ºå‰ç«¯å¯ç”¨æ ¼å¼
                yield self.transform_workflow_event(node_name, node_output)

        except Exception as e:
            yield {
                "type": "error",
                "content": f"å·¥ä½œæµæ‰§è¡Œé”™è¯¯: {str(e)}",
                "step": "execution",
                "error_details": str(e)
            }

    def process_query_sync(
        self,
        user_question: str,
        session_id: str = None
    ) -> List[Dict[str, Any]]:
        """
        åŒæ­¥å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼ˆç”¨äºStreamlitï¼‰
        æ”¯æŒHuman Reviewçš„ä¸­æ–­å’Œæ¢å¤
        """
        if not self.compiled_graph:
            return [{
                "type": "error",
                "content": "LangGraphå·¥ä½œæµæœªåˆå§‹åŒ–",
                "step": "initialization"
            }]

        try:
            # æ„å»ºè¾“å…¥çŠ¶æ€
            workflow_input = MainWorkflowState(
                user_question=user_question,
                session_id=session_id or f"session_{uuid.uuid4()}"
            )

            # ä½¿ç”¨å¯æ¢å¤çš„å·¥ä½œæµæ‰§è¡Œ
            return self.execute_with_checkpoints(workflow_input, session_id)

        except Exception as e:
            return [{
                "type": "error",
                "content": f"å·¥ä½œæµæ‰§è¡Œé”™è¯¯: {str(e)}",
                "step": "execution",
                "error_details": str(e)
            }]

    def process_final_state(self, state: MainWorkflowState) -> Dict[str, Any]:
        """å¤„ç†å·¥ä½œæµæœ€ç»ˆçŠ¶æ€"""

        # ç±»å‹æ£€æŸ¥å’Œå®‰å…¨å¤„ç†
        if not isinstance(state, dict):
            print(f"é”™è¯¯ï¼šæ”¶åˆ°éå­—å…¸ç±»å‹çš„çŠ¶æ€: {type(state)}")
            return {
                "type": "error",
                "content": f"çŠ¶æ€ç±»å‹é”™è¯¯: æœŸæœ›å­—å…¸ï¼Œæ”¶åˆ° {type(state)}",
                "step": "process_final_state"
            }

        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        print(f"å¤„ç†æœ€ç»ˆçŠ¶æ€ï¼Œå½“å‰æ­¥éª¤: {state.get('current_step', 'unknown')}")
        print(f"å·¥ä½œæµçŠ¶æ€: {state.get('workflow_status', 'unknown')}")

        # æ£€æŸ¥æ˜¯å¦æœ‰explanationï¼Œå¦‚æœæœ‰åˆ™å¯èƒ½éœ€è¦human review
        has_explanation = bool(state.get('explanation_markdown', ''))
        has_human_review = bool(state.get('review_decision', ''))

        print(f"æ˜¯å¦æœ‰è§£é‡Š: {has_explanation}, æ˜¯å¦æœ‰human review: {has_human_review}")

        # ä»æ‰§è¡Œç»“æœä¸­æå–æŸ¥è¯¢æ•°æ®
        execution_result = state.get('execution_result', {})
        query_results = execution_result.get('results', [])
        sql_query = state.get('generated_sql', '')
        visualization_config = state.get('visualization_config', {})
        analysis_insights = state.get('analysis_insights', [])

        # è½¬æ¢æŸ¥è¯¢ç»“æœä¸ºDataFrame
        data = None
        if query_results:
            try:
                data = pd.DataFrame(query_results)
                print(f"âœ… æˆåŠŸè½¬æ¢ {len(query_results)} è¡Œæ•°æ®ä¸ºDataFrame")
            except Exception as e:
                st.warning(f"æ•°æ®è½¬æ¢å¤±è´¥: {str(e)}")
                data = pd.DataFrame()
        else:
            print("âš ï¸ æœªæ‰¾åˆ°æŸ¥è¯¢ç»“æœæ•°æ®")
            data = pd.DataFrame()

        # ç”Ÿæˆåˆ†ææ´å¯Ÿï¼ˆåŸºäºå®é™…æ•°æ®å†…å®¹ï¼‰
        if not analysis_insights and data is not None and not data.empty:
            row_count = len(data)

            # è·å–æ•°æ®åˆ—ä¿¡æ¯
            columns = list(data.columns)

            # æ ¹æ®å®é™…æ•°æ®ç”Ÿæˆæ´å¯Ÿ
            insights = [f"æŸ¥è¯¢è¿”å› {row_count:,} æ¡è®°å½•"]

            # å¦‚æœæœ‰æ•°å€¼åˆ—ï¼Œæ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            numeric_columns = data.select_dtypes(include=['number']).columns.tolist()
            if numeric_columns:
                insights.append(f"åŒ…å« {len(numeric_columns)} ä¸ªæ•°å€¼å­—æ®µ: {', '.join(numeric_columns[:3])}")

            # å¦‚æœæœ‰ç‰¹å®šçš„ä¸šåŠ¡å­—æ®µï¼Œæ·»åŠ ç›¸å…³ä¿¡æ¯
            if 'listing_status' in columns:
                try:
                    discontinued_data = data[data['listing_status'] == 'Discontinued']
                    if not discontinued_data.empty and 'product_count' in columns:
                        discontinued_count = discontinued_data['product_count'].sum()
                        insights.append(f"åŒ…å« {discontinued_count:,} ä¸ªDiscontinuedçŠ¶æ€äº§å“")
                except Exception as e:
                    print(f"å¤„ç†listing_statusæ—¶å‡ºé”™: {e}")

            if 'brand' in columns or 'brand_name' in columns:
                brand_col = 'brand' if 'brand' in columns else 'brand_name'
                try:
                    unique_brands = data[brand_col].nunique()
                    insights.append(f"æ¶‰åŠ {unique_brands} ä¸ªä¸åŒå“ç‰Œ")
                except Exception as e:
                    print(f"å¤„ç†å“ç‰Œä¿¡æ¯æ—¶å‡ºé”™: {e}")

            analysis_insights = insights

        # process_final_state ç°åœ¨åªå¤„ç†æœ€ç»ˆç»“æœï¼Œä¸å†åŒ…å«human reviewé€»è¾‘
        # human reviewé€»è¾‘å·²ç§»åˆ° execute_with_checkpoints ä¸­å¤„ç†
        print(f"è°ƒè¯•ï¼šprocess_final_state è¢«è°ƒç”¨ï¼Œhas_explanation={has_explanation}, has_human_review={has_human_review}")

        return {
            "type": "final_result",
            "content": "åˆ†æå®Œæˆ",
            "step": "completed",
            "title": "âœ… åˆ†æå®Œæˆ",
            "success": True,
            "data": {
                "sql_query": sql_query,
                "query_results": data,
                "visualization_config": visualization_config,
                "insights": analysis_insights,
                "execution_time": state.get('execution_time', 0),
                "record_count": len(query_results) if query_results else 0,
                "report_path": state.get('report_path', ''),
                "data_summary": {
                    "columns": list(data.columns) if data is not None and not data.empty else [],
                    "shape": data.shape if data is not None else (0, 0)
                }
            }
        }

    def transform_workflow_event(self, node_name: str, node_output: Dict) -> Dict[str, Any]:
        """è½¬æ¢å·¥ä½œæµäº‹ä»¶ä¸ºå‰ç«¯æ ¼å¼"""

        event_mappings = {
            "initialize_session": {
                "type": "initialization",
                "step": "session_init",
                "title": "ğŸ”§ ä¼šè¯åˆå§‹åŒ–"
            },
            "analyze_question": {
                "type": "analysis",
                "step": "question_analysis",
                "title": "ğŸ” é—®é¢˜åˆ†æ"
            },
            "generate_query": {
                "type": "generation",
                "step": "query_generation",
                "title": "ğŸ“ SQLç”Ÿæˆ"
            },
            "execute_script": {
                "type": "execution",
                "step": "query_execution",
                "title": "âš¡ æŸ¥è¯¢æ‰§è¡Œ"
            },
            "validate_results": {
                "type": "validation",
                "step": "validation",
                "title": "âœ… ç»“æœéªŒè¯"
            },
            "generate_visualization": {
                "type": "visualization",
                "step": "visualization",
                "title": "ğŸ“Š æ•°æ®å¯è§†åŒ–"
            },
            "human_review": {
                "type": "review",
                "step": "human_review",
                "title": "ğŸ‘¤ äººå·¥å®¡æŸ¥"
            },
            "finalize_workflow": {
                "type": "finalization",
                "step": "finalization",
                "title": "ğŸ¯ å®Œæˆåˆ†æ"
            },
            "handle_error": {
                "type": "error_handling",
                "step": "error_handling",
                "title": "ğŸš¨ é”™è¯¯å¤„ç†"
            }
        }

        mapping = event_mappings.get(node_name, {
            "type": "unknown",
            "step": node_name,
            "title": f"ğŸ“‹ {node_name}"
        })

        return {
            **mapping,
            "content": self.extract_content_from_output(node_output),
            "data": node_output,
            "timestamp": datetime.now().isoformat(),
            "success": not node_output.get("error", False)
        }

    def extract_content_from_output(self, node_output: Dict) -> str:
        """ä»èŠ‚ç‚¹è¾“å‡ºä¸­æå–å†…å®¹ä¿¡æ¯"""

        if isinstance(node_output, dict):
            # å°è¯•æå–ä¸åŒç±»å‹çš„å†…å®¹
            content_fields = ['message', 'output', 'result', 'summary', 'description']

            for field in content_fields:
                if field in node_output and node_output[field]:
                    return str(node_output[field])

            # å¦‚æœæœ‰SQLæŸ¥è¯¢ï¼Œæ˜¾ç¤ºSQL
            if 'generated_sql' in node_output:
                return f"ç”ŸæˆSQL: {node_output['generated_sql'][:100]}..."

            # å¦‚æœæœ‰æŸ¥è¯¢ç»“æœï¼Œæ˜¾ç¤ºè®°å½•æ•°
            if 'query_results' in node_output:
                results = node_output['query_results']
                if isinstance(results, list):
                    return f"æŸ¥è¯¢è¿”å› {len(results)} æ¡è®°å½•"

            # é»˜è®¤æ˜¾ç¤ºèŠ‚ç‚¹åç§°
            return f"èŠ‚ç‚¹ {node_output.get('node_name', 'unknown')} æ‰§è¡Œå®Œæˆ"

        return str(node_output) if node_output else "èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ"

    def validate_connection(self) -> bool:
        """éªŒè¯LangGraphè¿æ¥çŠ¶æ€"""
        return self.compiled_graph is not None and LANGGRAPH_AVAILABLE

    def execute_with_checkpoints(self, workflow_input: MainWorkflowState, session_id: str) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨checkpointæ‰§è¡Œå·¥ä½œæµï¼Œæ”¯æŒä¸­æ–­å’Œæ¢å¤
        ä½¿ç”¨æµå¼æ‰§è¡Œæ¥æ­£ç¡®å¤„ç†interrupts
        """
        thread_id = session_id or workflow_input.get("session_id", f"session_{uuid.uuid4()}")
        config = {
            "configurable": {"thread_id": thread_id},
            "recursion_limit": 50
        }

        try:
            # ä½¿ç”¨æµå¼æ‰§è¡Œæ¥æ­£ç¡®å¤„ç†ä¸­æ–­
            events = []
            final_state = None

            # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰å·²ç»å­˜åœ¨çš„çŠ¶æ€ï¼ˆä¾‹å¦‚ä»ä¸­æ–­æ¢å¤ï¼‰
            try:
                current_state = self.compiled_graph.get_state(config)
                if current_state and current_state.next:
                    print(f"å‘ç°å·²å­˜åœ¨çš„å·¥ä½œæµçŠ¶æ€ï¼Œå½“å‰æ­¥éª¤: {current_state.next}")
            except Exception as e:
                print(f"æ£€æŸ¥ç°æœ‰çŠ¶æ€æ—¶å‡ºé”™: {e}")

            # ä½¿ç”¨æµå¼æ‰§è¡Œ
            for event in self.compiled_graph.stream(workflow_input, config=config):
                events.append(event)
                # è·å–æœ€æ–°çŠ¶æ€
                if isinstance(event, dict) and len(event) > 0:
                    node_name = list(event.keys())[0]
                    final_state = event[node_name]
                    print(f"æ‰§è¡ŒèŠ‚ç‚¹: {node_name}")

            # æ£€æŸ¥å·¥ä½œæµæ˜¯å¦æ­£å¸¸å®Œæˆ
            if final_state:
                print(f"è°ƒè¯•ï¼šå·¥ä½œæµå®Œæˆï¼Œfinal_state keys: {list(final_state.keys()) if isinstance(final_state, dict) else 'not dict'}")

                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾äº†éœ€è¦human reviewçš„çŠ¶æ€
                current_graph_state = self.compiled_graph.get_state(config)
                print(f"è°ƒè¯•ï¼šè·å–å½“å‰å›¾çŠ¶æ€: {current_graph_state is not None}")

                if current_graph_state and current_graph_state.next:
                    next_steps = current_graph_state.next
                    print(f"å·¥ä½œæµä¸­æ–­ï¼Œç­‰å¾…æ­¥éª¤: {next_steps}")

                    # æ£€æŸ¥æ˜¯å¦åœ¨human_reviewèŠ‚ç‚¹ç­‰å¾…
                    if 'human_review' in next_steps:
                        print(f"è°ƒè¯•ï¼šæ£€æµ‹åˆ°human_reviewä¸­æ–­ï¼Œè°ƒç”¨handle_human_review_interrupt")
                        return self.handle_human_review_interrupt(thread_id, config, "Workflow interrupted at human_review")
                    else:
                        print(f"è°ƒè¯•ï¼šä¸­æ–­çŠ¶æ€ä½†ä¸æ˜¯human_review: {next_steps}")
                elif current_graph_state:
                    print(f"è°ƒè¯•ï¼šå·¥ä½œæµçŠ¶æ€å­˜åœ¨ä½†æ²¡æœ‰nextæ­¥éª¤")
                else:
                    print(f"è°ƒè¯•ï¼šæ— æ³•è·å–å½“å‰å›¾çŠ¶æ€")

                # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœå·¥ä½œæµåˆ°è¾¾äº† explain_results ä½†æ²¡æœ‰è¿›å…¥ human_reviewï¼Œå¼ºåˆ¶è§¦å‘
                has_explanation = bool(final_state.get('explanation_markdown', ''))
                current_step = final_state.get('current_step', '')

                print(f"è°ƒè¯•ï¼šæ£€æŸ¥explain_resultsç‰¹æ®Šæƒ…å†µ - has_explanation: {has_explanation}, current_step: {current_step}")

                if has_explanation and current_step == 'human_review':
                    print(f"è°ƒè¯•ï¼šæ£€æµ‹åˆ°explain_resultså®Œæˆä½†æœªè§¦å‘human_reviewï¼Œå¼ºåˆ¶è§¦å‘")
                    return self.handle_human_review_interrupt(thread_id, config, "Force human review after explain_results")

                # æ–°çš„é€»è¾‘ï¼šé»˜è®¤æ‰€æœ‰æˆåŠŸæ‰§è¡Œçš„æŸ¥è¯¢éƒ½éœ€è¦human review
                print(f"è°ƒè¯•ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦human review...")

                # æ£€æŸ¥å·¥ä½œæµçš„æœ€ç»ˆçŠ¶æ€ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦human review
                should_review = self.should_trigger_human_review(final_state)
                print(f"è°ƒè¯•ï¼šshould_trigger_human_review è¿”å›: {should_review}")

                if should_review:
                    print(f"è°ƒè¯•ï¼šè§¦å‘human review")
                    return self.handle_human_review_interrupt(thread_id, config, "Human review required based on workflow state")

                # å·¥ä½œæµæ­£å¸¸å®Œæˆï¼ˆä½†è¿™ç§æƒ…å†µç°åœ¨åº”è¯¥å¾ˆå°‘è§ï¼Œå› ä¸ºæˆ‘ä»¬é»˜è®¤éƒ½éœ€è¦reviewï¼‰
                print(f"è°ƒè¯•ï¼šå·¥ä½œæµæ­£å¸¸å®Œæˆï¼Œæ— éœ€human review")
                result = self.process_final_state(final_state)
                return [result]
            else:
                return [{
                    "type": "error",
                    "content": "å·¥ä½œæµæ‰§è¡Œæœªè¿”å›æœ€ç»ˆçŠ¶æ€",
                    "step": "execution"
                }]

        except Exception as e:
            error_str = str(e)
            print(f"å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸: {error_str}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯LangGraphçš„ä¸­æ–­å¼‚å¸¸
            if any(keyword in error_str.lower() for keyword in ["interrupt", "waiting", "human"]):
                return self.handle_human_review_interrupt(thread_id, config, error_str)
            else:
                # å…¶ä»–é”™è¯¯
                return [{
                    "type": "error",
                    "content": f"å·¥ä½œæµæ‰§è¡Œé”™è¯¯: {error_str}",
                    "step": "execution",
                    "error_details": error_str
                }]

    def handle_human_review_interrupt(self, thread_id: str, config: Dict, error_str: str) -> List[Dict[str, Any]]:
        """
        å¤„ç†äººå·¥å®¡æŸ¥ä¸­æ–­
        """
        print(f"è°ƒè¯•ï¼šhandle_human_review_interrupt è¢«è°ƒç”¨ - thread_id: {thread_id}")
        try:
            # è·å–å½“å‰çŠ¶æ€
            current_state = self.get_current_state(thread_id, config)
            print(f"è°ƒè¯•ï¼šè·å–åˆ°çš„å½“å‰çŠ¶æ€ç±»å‹: {type(current_state)}")

            if current_state:
                print(f"è°ƒè¯•ï¼šå½“å‰çŠ¶æ€keys: {list(current_state.keys()) if isinstance(current_state, dict) else 'not dict'}")

                # å­˜å‚¨å·¥ä½œæµçŠ¶æ€ä»¥ä¾›åç»­æ¢å¤
                self.pending_workflows[thread_id] = {
                    "state": current_state,
                    "config": config,
                    "timestamp": datetime.now().isoformat()
                }

                # æå–reviewæ•°æ®
                review_data = self.extract_review_data(current_state)
                print(f"è°ƒè¯•ï¼šæå–çš„review_data: {review_data is not None and len(review_data) > 0}")

                # è¿”å›äººå·¥å®¡æŸ¥çŠ¶æ€
                result = [{
                    "type": "human_review_required",
                    "content": "éœ€è¦äººå·¥å®¡æŸ¥",
                    "step": "human_review",
                    "thread_id": thread_id,
                    "review_data": review_data
                }]
                print(f"è°ƒè¯•ï¼šè¿”å›human_review_requiredç»“æœ")
                return result
            else:
                print(f"è°ƒè¯•ï¼šæ— æ³•è·å–å·¥ä½œæµçŠ¶æ€")
                return [{
                    "type": "error",
                    "content": "æ— æ³•è·å–å·¥ä½œæµçŠ¶æ€",
                    "step": "human_review"
                }]
        except Exception as e:
            print(f"è°ƒè¯•ï¼šhandle_human_review_interruptå¼‚å¸¸: {e}")
            return [{
                "type": "error",
                "content": f"å¤„ç†äººå·¥å®¡æŸ¥ä¸­æ–­å¤±è´¥: {str(e)}",
                "step": "human_review"
            }]

    def get_current_state(self, thread_id: str, config: Dict) -> Dict:
        """
        è·å–å½“å‰å·¥ä½œæµçŠ¶æ€
        """
        try:
            # è·å–checkpointçŠ¶æ€
            state_snapshot = self.compiled_graph.get_state(config)
            return state_snapshot.values if state_snapshot else None
        except Exception as e:
            print(f"è·å–çŠ¶æ€å¤±è´¥: {e}")
            return None

    def should_trigger_human_review(self, state: Dict) -> bool:
        """
        æ ¹æ®å·¥ä½œæµçŠ¶æ€åˆ¤æ–­æ˜¯å¦éœ€è¦è§¦å‘human review
        é»˜è®¤æ‰€æœ‰æˆåŠŸçš„æŸ¥è¯¢éƒ½éœ€è¦human review
        """
        if not state:
            print("è°ƒè¯•ï¼šçŠ¶æ€ä¸ºç©ºï¼Œä¸è§¦å‘human review")
            return False

        print(f"è°ƒè¯•ï¼šæ£€æŸ¥çŠ¶æ€çš„æ‰€æœ‰key: {list(state.keys())}")

        # æ£€æŸ¥å¤šç§å¯èƒ½çš„å®ŒæˆçŠ¶æ€æŒ‡æ ‡
        execution_result = state.get("execution_result", {})
        has_execution_success = bool(state.get("execution_success", False))
        has_execution_result = bool(execution_result.get("success", False))
        has_generated_sql = bool(state.get("generated_sql", ""))
        has_human_review = bool(state.get("review_decision", ""))
        has_explanation = bool(state.get("explanation_markdown", ""))

        print(f"è°ƒè¯•ï¼šhuman reviewè§¦å‘æ£€æŸ¥ (é»˜è®¤å¿…éœ€æ¨¡å¼):")
        print(f"  - has_execution_success: {has_execution_success}")
        print(f"  - has_execution_result: {has_execution_result}")
        print(f"  - has_generated_sql: {has_generated_sql}")
        print(f"  - has_explanation: {has_explanation}")
        print(f"  - has_human_review: {has_human_review}")
        print(f"  - execution_result keys: {list(execution_result.keys())}")

        # æ›´å®½æ¾çš„ç­–ç•¥ï¼šä»»ä½•æœ‰æ‰§è¡ŒæˆåŠŸæ ‡å¿—æˆ–æœ‰SQLç”Ÿæˆçš„ï¼Œä¸”è¿˜æ²¡æœ‰human reviewï¼Œå°±è§¦å‘
        # è¿™ç¡®ä¿å‡ ä¹æ‰€æœ‰æˆåŠŸçš„æŸ¥è¯¢éƒ½ä¼šè§¦å‘human review
        should_trigger = (
            (has_execution_success or has_execution_result or has_generated_sql)
            and not has_human_review
        )

        print(f"  - æœ€ç»ˆå†³å®šï¼šshould_trigger_human_review = {should_trigger}")
        return should_trigger

    def extract_review_data(self, state: Dict) -> Dict:
        """
        ä»çŠ¶æ€ä¸­æå–äººå·¥å®¡æŸ¥æ‰€éœ€çš„æ•°æ®
        """
        if not state:
            return {}

        execution_result = state.get("execution_result", {})
        data_sample = execution_result.get("results", [])[:10]  # å‰10æ¡è®°å½•

        # æ¨èå›¾è¡¨ç±»å‹
        recommended_charts = ["table", "bar_chart"]
        if len(data_sample) > 0:
            first_row = data_sample[0]
            numeric_cols = [k for k, v in first_row.items() if isinstance(v, (int, float))]
            if numeric_cols:
                recommended_charts.append("line_chart")

        return {
            "user_question": state.get("user_question", ""),
            "explanation": state.get("explanation_markdown", "No explanation available."),
            "validation_reasoning": state.get("validation_reasoning", ""),
            "data_summary": {
                "total_rows": len(execution_result.get("results", [])),
                "has_data": len(data_sample) > 0,
                "execution_success": execution_result.get("success", False)
            },
            "data_sample": data_sample,
            "recommended_charts": recommended_charts,
            "available_charts": ["table", "bar_chart", "line_chart", "pie_chart", "scatter_plot"]
        }

    def resume_workflow_with_human_input(self, thread_id: str, human_response: Dict) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨äººç±»è¾“å…¥æ¢å¤å·¥ä½œæµ
        ä¼˜å…ˆä½¿ç”¨ç›´æ¥æ¢å¤æ–¹å¼ï¼Œå› ä¸ºçŠ¶æ€ä¿å­˜åœ¨å…±äº«checkpointerä¸­
        """
        print(f"å¼€å§‹æ¢å¤å·¥ä½œæµ {thread_id}")

        # ç›´æ¥å°è¯•æ¢å¤ï¼Œå› ä¸ºçŠ¶æ€ä¿å­˜åœ¨å…±äº«checkpointerä¸­
        try:
            return self.try_direct_resume(thread_id, human_response)
        except Exception as e:
            print(f"ç›´æ¥æ¢å¤å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ: {e}")

            # å¤‡ç”¨æ–¹æ¡ˆï¼šä»pending_workflowsæ¢å¤
            if thread_id not in self.pending_workflows:
                return [{
                    "type": "error",
                    "content": f"æ— æ³•æ‰¾åˆ°å·¥ä½œæµçŠ¶æ€: {thread_id}",
                    "step": "resume"
                }]

            try:
                # è·å–å­˜å‚¨çš„å·¥ä½œæµä¿¡æ¯
                workflow_info = self.pending_workflows[thread_id]
                config = workflow_info["config"]

                # ä½¿ç”¨äººç±»è¾“å…¥æ›´æ–°çŠ¶æ€
                state_update = self.prepare_human_response_update(human_response)

                # æ¢å¤å·¥ä½œæµæ‰§è¡Œ
                print(f"æ¢å¤å·¥ä½œæµï¼Œä½¿ç”¨çŠ¶æ€æ›´æ–°: {state_update}")
                final_state = self.compiled_graph.invoke(state_update, config=config)

                # æ¸…ç†å­˜å‚¨çš„å·¥ä½œæµçŠ¶æ€
                del self.pending_workflows[thread_id]

                # å¤„ç†æœ€ç»ˆçŠ¶æ€
                result = self.process_final_state(final_state)
                return [result]

            except Exception as e2:
                return [{
                    "type": "error",
                    "content": f"æ¢å¤å·¥ä½œæµå¤±è´¥: {str(e2)}",
                    "step": "resume",
                    "error_details": str(e2)
                }]

    def try_direct_resume(self, thread_id: str, human_response: Dict) -> List[Dict[str, Any]]:
        """
        å°è¯•ç›´æ¥æ¢å¤å·¥ä½œæµï¼ˆä½¿ç”¨å…±äº«checkpointerä¸­çš„çŠ¶æ€ï¼‰
        """
        config = {
            "configurable": {"thread_id": thread_id},
            "recursion_limit": 50
        }

        try:
            # æ£€æŸ¥å½“å‰çŠ¶æ€
            current_state = self.compiled_graph.get_state(config)
            if not current_state:
                return [{
                    "type": "error",
                    "content": "æ— æ³•è·å–å·¥ä½œæµçŠ¶æ€",
                    "step": "resume"
                }]

            print(f"å½“å‰å·¥ä½œæµçŠ¶æ€: next={current_state.next}")

            # å¦‚æœå·¥ä½œæµä¸åœ¨ç­‰å¾…çŠ¶æ€ï¼Œè¿”å›é”™è¯¯
            if not current_state.next:
                return [{
                    "type": "error",
                    "content": "å·¥ä½œæµæœªå¤„äºç­‰å¾…çŠ¶æ€",
                    "step": "resume"
                }]

            # å‡†å¤‡äººç±»å“åº”æ›´æ–°
            state_update = self.prepare_human_response_update(human_response)
            print(f"å‡†å¤‡çš„çŠ¶æ€æ›´æ–°: {state_update}")

            # ä½¿ç”¨update_stateæ–¹æ³•æ›´æ–°çŠ¶æ€
            self.compiled_graph.update_state(config, state_update)

            # ç»§ç»­æ‰§è¡Œå·¥ä½œæµ
            final_state = None
            for event in self.compiled_graph.stream(None, config=config):
                if isinstance(event, dict) and len(event) > 0:
                    node_name = list(event.keys())[0]
                    final_state = event[node_name]
                    print(f"æ¢å¤æ‰§è¡ŒèŠ‚ç‚¹: {node_name}")

            if final_state:
                # å¤„ç†æœ€ç»ˆçŠ¶æ€
                result = self.process_final_state(final_state)
                return [result]
            else:
                return [{
                    "type": "error",
                    "content": "æ¢å¤åå·¥ä½œæµæœªäº§ç”Ÿæœ€ç»ˆçŠ¶æ€",
                    "step": "resume"
                }]

        except Exception as e:
            return [{
                "type": "error",
                "content": f"ç›´æ¥æ¢å¤å¤±è´¥: {str(e)}",
                "step": "resume",
                "error_details": str(e)
            }]

    def prepare_human_response_update(self, human_response: Dict) -> Dict:
        """
        å‡†å¤‡äººç±»å“åº”çš„çŠ¶æ€æ›´æ–°
        """
        decision = human_response.get("decision", "approve")
        chart_selection = human_response.get("chart_selection", "table")
        preferences = human_response.get("preferences", {})
        modifications = human_response.get("modifications", [])

        # éªŒè¯å’Œè®¾ç½®é»˜è®¤åå¥½
        if chart_selection == "bar_chart":
            preferences.setdefault("orientation", "vertical")
            preferences.setdefault("color_scheme", "default")
        elif chart_selection == "line_chart":
            preferences.setdefault("show_markers", True)
        elif chart_selection == "pie_chart":
            preferences.setdefault("show_percentages", True)

        preferences.setdefault("include_data_table", True)
        preferences.setdefault("title", "Analysis Results")

        return {
            "user_chart_selection": chart_selection,
            "user_preferences": preferences,
            "review_decision": decision,
            "modification_requests": modifications
        }

    def is_workflow_pending_review(self, thread_id: str) -> bool:
        """
        æ£€æŸ¥å·¥ä½œæµæ˜¯å¦æ­£åœ¨ç­‰å¾…äººå·¥å®¡æŸ¥
        """
        return thread_id in self.pending_workflows

    def get_pending_review_data(self, thread_id: str) -> Dict:
        """
        è·å–ç­‰å¾…å®¡æŸ¥çš„æ•°æ®
        """
        if thread_id in self.pending_workflows:
            workflow_info = self.pending_workflows[thread_id]
            state = workflow_info["state"]
            return self.extract_review_data(state)
        return {}

class StreamlitWorkflowRunner:
    """Streamlitç¯å¢ƒä¸‹çš„å·¥ä½œæµè¿è¡Œå™¨"""

    def __init__(self):
        self.integration = LangGraphIntegration()

    def run_query_workflow(self, question: str, session_id: str = None) -> Dict[str, Any]:
        """åœ¨Streamlitä¸­è¿è¡ŒæŸ¥è¯¢å·¥ä½œæµ"""

        # æ›´æ–°å·¥ä½œæµçŠ¶æ€
        st.session_state.workflow_status = "running"
        st.session_state.current_step = 0

        try:
            # è¿è¡ŒåŒæ­¥å·¥ä½œæµ
            results = self.integration.process_query_sync(question, session_id)

            # æ›´æ–°å®ŒæˆçŠ¶æ€
            st.session_state.workflow_status = "completed"

            # æ£€æŸ¥æ˜¯å¦æœ‰human_review_requiredçš„ç»“æœ
            if results:
                # ä¼˜å…ˆæŸ¥æ‰¾human_review_requiredç±»å‹çš„ç»“æœ
                for result in results:
                    if result.get('type') == 'human_review_required':
                        print(f"è°ƒè¯•ï¼šæ‰¾åˆ°human_review_requiredç»“æœ")
                        return result

                # å¦‚æœæ²¡æœ‰human_review_requiredï¼Œè¿”å›æœ€åä¸€ä¸ªç»“æœ
                final_result = results[-1]
                print(f"è°ƒè¯•ï¼šæ²¡æœ‰æ‰¾åˆ°human_review_requiredï¼Œè¿”å›æœ€ç»ˆç»“æœç±»å‹: {final_result.get('type')}")

                # æ›´æ–°session state
                if final_result.get('data'):
                    data = final_result['data']
                    st.session_state.generated_sql = data.get('sql_query', '')
                    st.session_state.query_results = data.get('query_results')
                    st.session_state.visualization_config = data.get('visualization_config', {})

                return final_result

            return {"type": "error", "content": "æœªæ”¶åˆ°å·¥ä½œæµç»“æœ"}

        except Exception as e:
            st.session_state.workflow_status = "error"
            st.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
            return {
                "type": "error",
                "content": f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}",
                "error_details": str(e)
            }

def get_workflow_runner() -> StreamlitWorkflowRunner:
    """è·å–å·¥ä½œæµè¿è¡Œå™¨å®ä¾‹"""
    if "workflow_runner" not in st.session_state:
        st.session_state.workflow_runner = StreamlitWorkflowRunner()

    return st.session_state.workflow_runner

def test_langgraph_connection() -> bool:
    """æµ‹è¯•LangGraphè¿æ¥"""
    runner = get_workflow_runner()
    return runner.integration.validate_connection()

def process_user_query(query: str, session_id: str = None) -> Dict[str, Any]:
    """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
    runner = get_workflow_runner()

    if not runner.integration.validate_connection():
        raise Exception("LangGraphå·¥ä½œæµæœªæ­£ç¡®åˆå§‹åŒ–")

    # è¿è¡Œå·¥ä½œæµ
    result = runner.run_query_workflow(query, session_id)

    # æ›´æ–°session state
    st.session_state.current_query = query

    return result

def resume_workflow_with_review(thread_id: str, human_response: Dict) -> Dict[str, Any]:
    """ä½¿ç”¨äººå·¥å®¡æŸ¥ç»“æœæ¢å¤å·¥ä½œæµ"""
    runner = get_workflow_runner()

    if not runner.integration.validate_connection():
        raise Exception("LangGraphå·¥ä½œæµæœªæ­£ç¡®åˆå§‹åŒ–")

    # æ¢å¤å·¥ä½œæµ
    results = runner.integration.resume_workflow_with_human_input(thread_id, human_response)

    if results:
        return results[0]
    else:
        return {
            "type": "error",
            "content": "æ¢å¤å·¥ä½œæµå¤±è´¥"
        }

def check_pending_review(thread_id: str) -> Dict[str, Any]:
    """æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…å®¡æŸ¥çš„å·¥ä½œæµ"""
    runner = get_workflow_runner()

    if runner.integration.is_workflow_pending_review(thread_id):
        review_data = runner.integration.get_pending_review_data(thread_id)
        return {
            "pending": True,
            "review_data": review_data
        }
    else:
        return {
            "pending": False
        }

def get_recent_queries() -> List[Dict]:
    """è·å–æœ€è¿‘çš„æŸ¥è¯¢å†å²"""
    chat_history = st.session_state.get("chat_history", [])
    return chat_history[-5:]  # æœ€è¿‘5æ¬¡å¯¹è¯

def get_user_feedback() -> Dict:
    """è·å–ç”¨æˆ·åé¦ˆä¿¡æ¯"""
    return st.session_state.get("user_feedback", {})