# Task 05: æµ‹è¯•éƒ¨ç½²

## ä»»åŠ¡æ¦‚è¿°
å®Œæˆåº”ç”¨çš„å…¨é¢æµ‹è¯•ã€æ€§èƒ½ä¼˜åŒ–éªŒè¯å’Œç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å‡†å¤‡ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šå¯é è¿è¡Œã€‚

## å®æ–½ç›®æ ‡
- å®ç°å®Œæ•´çš„æµ‹è¯•è¦†ç›–
- éªŒè¯ç”Ÿäº§ç¯å¢ƒå…¼å®¹æ€§
- å»ºç«‹CI/CDæµç¨‹
- é…ç½®ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ
- å‡†å¤‡éƒ¨ç½²æ–‡æ¡£

## æŠ€æœ¯å®ç°

### 1. æµ‹è¯•æ¡†æ¶æ­å»º (tests/test_framework.py)

```python
"""
Streamlitåº”ç”¨æµ‹è¯•æ¡†æ¶
ä½¿ç”¨Streamlitå®˜æ–¹æµ‹è¯•å·¥å…·è¿›è¡Œå…¨é¢æµ‹è¯•
"""

import pytest
import streamlit as st
from streamlit.testing.v1 import AppTest
import pandas as pd
import time
from typing import Dict, Any, List
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

class StreamlitTestSuite:
    """Streamlitæµ‹è¯•å¥—ä»¶"""

    def __init__(self):
        self.setup_test_environment()

    def setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # è®¾ç½®æµ‹è¯•æ¨¡å¼
        os.environ['STREAMLIT_TESTING'] = 'true'

    def test_main_app(self):
        """æµ‹è¯•ä¸»åº”ç”¨"""
        at = AppTest.from_file("main.py")
        at.run()

        # æ£€æŸ¥é¡µé¢æ ‡é¢˜
        assert len(at.title) > 0
        assert "AIæ•°æ®åº“åˆ†æå¸ˆ" in at.title[0].value

        # æ£€æŸ¥åŸºæœ¬ç»„ä»¶
        assert len(at.sidebar) > 0
        assert len(at.markdown) > 0

    def test_chat_page(self):
        """æµ‹è¯•èŠå¤©é¡µé¢"""
        at = AppTest.from_file("pages/1_ğŸ’¬_Chat.py")
        at.run()

        # æ£€æŸ¥èŠå¤©ç•Œé¢ç»„ä»¶
        assert len(at.title) > 0
        assert "èŠå¤©" in at.title[0].value

        # æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥
        if len(at.chat_input) > 0:
            at.chat_input[0].set_value("æµ‹è¯•æŸ¥è¯¢").run()

            # æ£€æŸ¥æ˜¯å¦æœ‰èŠå¤©æ¶ˆæ¯
            assert len(at.chat_message) > 0

    def test_analysis_page(self):
        """æµ‹è¯•åˆ†æé¡µé¢"""
        at = AppTest.from_file("pages/2_ğŸ“Š_Analysis.py")

        # è®¾ç½®æµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'date': pd.date_range('2024-01-01', periods=10),
            'value': range(10),
            'category': ['A', 'B'] * 5
        })

        at.session_state['analysis_results'] = [{
            'title': 'æµ‹è¯•åˆ†æ',
            'data': test_data,
            'success': True,
            'execution_time': 1.5
        }]

        at.run()

        # æ£€æŸ¥åˆ†æç»“æœæ˜¾ç¤º
        assert len(at.dataframe) > 0

    def test_settings_page(self):
        """æµ‹è¯•è®¾ç½®é¡µé¢"""
        at = AppTest.from_file("pages/3_ğŸ”§_Settings.py")
        at.run()

        # æ£€æŸ¥è®¾ç½®é€‰é¡¹
        assert len(at.selectbox) > 0
        assert len(at.tabs) > 0

        # æµ‹è¯•è®¾ç½®ä¿å­˜
        if len(at.button) > 0:
            save_button = None
            for button in at.button:
                if "ä¿å­˜" in button.label:
                    save_button = button
                    break

            if save_button:
                save_button.click().run()

    def test_session_state_management(self):
        """æµ‹è¯•Session Stateç®¡ç†"""
        at = AppTest.from_file("main.py")

        # è®¾ç½®æµ‹è¯•çŠ¶æ€
        at.session_state["test_key"] = "test_value"
        at.run()

        # éªŒè¯çŠ¶æ€ä¿æŒ
        assert at.session_state["test_key"] == "test_value"

    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        at = AppTest.from_file("main.py")

        # æ¨¡æ‹Ÿé”™è¯¯çŠ¶æ€
        at.session_state["error_history"] = [{
            'timestamp': time.time(),
            'context': 'test',
            'error_type': 'TestError',
            'error_message': 'Test error message'
        }]

        at.run()

        # æ£€æŸ¥åº”ç”¨æ˜¯å¦æ­£å¸¸å¤„ç†é”™è¯¯
        assert len(at.error) == 0  # ä¸åº”è¯¥æœ‰æœªå¤„ç†çš„é”™è¯¯

    def test_performance_metrics(self):
        """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡"""
        at = AppTest.from_file("pages/3_ğŸ”§_Settings.py")

        # è®¾ç½®æ€§èƒ½æ•°æ®
        at.session_state["performance_metrics"] = {
            'response_times': [
                {'operation': 'test', 'duration': 1.0, 'timestamp': time.time()}
            ],
            'memory_usage': [
                {'rss': 100, 'vms': 200, 'timestamp': time.time()}
            ]
        }

        at.run()

        # éªŒè¯æ€§èƒ½ç›‘æ§é¡µé¢
        performance_tab_found = False
        for tab in at.tabs:
            if "æ€§èƒ½ç›‘æ§" in tab.label:
                performance_tab_found = True
                break

        assert performance_tab_found

    def test_data_export_functionality(self):
        """æµ‹è¯•æ•°æ®å¯¼å‡ºåŠŸèƒ½"""
        at = AppTest.from_file("pages/2_ğŸ“Š_Analysis.py")

        # è®¾ç½®æµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})
        at.session_state['analysis_results'] = [{
            'data': test_data,
            'title': 'Test Export'
        }]

        at.run()

        # æ£€æŸ¥å¯¼å‡ºæŒ‰é’®
        export_button_found = False
        for button in at.button:
            if "ä¸‹è½½" in button.label or "å¯¼å‡º" in button.label:
                export_button_found = True
                break

        assert export_button_found

def run_component_tests():
    """è¿è¡Œç»„ä»¶æµ‹è¯•"""
    print("å¼€å§‹ç»„ä»¶æµ‹è¯•...")

    # æµ‹è¯•èŠå¤©ç»„ä»¶
    test_chat_component()

    # æµ‹è¯•å›¾è¡¨ç»„ä»¶
    test_chart_component()

    # æµ‹è¯•å·¥ä½œæµç»„ä»¶
    test_workflow_component()

    print("ç»„ä»¶æµ‹è¯•å®Œæˆï¼")

def test_chat_component():
    """æµ‹è¯•èŠå¤©ç»„ä»¶"""
    from components.chat_interface import ChatInterface

    # åˆ›å»ºèŠå¤©ç»„ä»¶å®ä¾‹
    chat = ChatInterface()

    # æµ‹è¯•åˆå§‹åŒ–
    assert hasattr(chat, 'initialize_chat_state')

    # æµ‹è¯•æ¶ˆæ¯æ·»åŠ 
    chat.add_message("user", "æµ‹è¯•æ¶ˆæ¯")
    assert len(st.session_state.get('chat_messages', [])) > 0

def test_chart_component():
    """æµ‹è¯•å›¾è¡¨ç»„ä»¶"""
    from components.chart_renderer import ChartRenderer

    # åˆ›å»ºå›¾è¡¨ç»„ä»¶å®ä¾‹
    chart_renderer = ChartRenderer()

    # æµ‹è¯•å›¾è¡¨ç±»å‹å»ºè®®
    test_data = pd.DataFrame({
        'x': range(10),
        'y': range(10, 20),
        'category': ['A', 'B'] * 5
    })

    suggested_type = chart_renderer.auto_suggest_chart_type(test_data)
    assert suggested_type in chart_renderer.supported_charts

def test_workflow_component():
    """æµ‹è¯•å·¥ä½œæµç»„ä»¶"""
    from components.workflow_display import WorkflowDisplay

    # åˆ›å»ºå·¥ä½œæµç»„ä»¶å®ä¾‹
    workflow = WorkflowDisplay()

    # æµ‹è¯•å·¥ä½œæµå¯åŠ¨
    test_steps = [
        {"name": "æµ‹è¯•æ­¥éª¤1", "description": "æµ‹è¯•æè¿°", "status": "pending"}
    ]

    workflow.start_workflow(test_steps)
    assert st.session_state.get('workflow_status') == 'running'

def run_integration_tests():
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    print("å¼€å§‹é›†æˆæµ‹è¯•...")

    # æµ‹è¯•LangGraphé›†æˆ
    test_langgraph_integration()

    # æµ‹è¯•ç¼“å­˜ç³»ç»Ÿ
    test_cache_system()

    # æµ‹è¯•é”™è¯¯å¤„ç†ç³»ç»Ÿ
    test_error_system()

    print("é›†æˆæµ‹è¯•å®Œæˆï¼")

def test_langgraph_integration():
    """æµ‹è¯•LangGraphé›†æˆ"""
    try:
        from utils.langgraph_integration import LangGraphIntegration

        # åˆ›å»ºé›†æˆå®ä¾‹
        integration = LangGraphIntegration()

        # æµ‹è¯•è¿æ¥éªŒè¯
        is_connected = integration.validate_connection()
        print(f"LangGraphè¿æ¥çŠ¶æ€: {is_connected}")

    except ImportError:
        print("LangGraphæ¨¡å—æœªå®‰è£…ï¼Œè·³è¿‡é›†æˆæµ‹è¯•")

def test_cache_system():
    """æµ‹è¯•ç¼“å­˜ç³»ç»Ÿ"""
    from utils.cache_manager import CacheManager

    cache_manager = CacheManager()

    # æµ‹è¯•ç¼“å­˜åŠŸèƒ½
    test_data = pd.DataFrame({'test': [1, 2, 3]})
    cached_result = cache_manager.cache_query_results("SELECT * FROM test", {})

    assert isinstance(cached_result, pd.DataFrame)

def test_error_system():
    """æµ‹è¯•é”™è¯¯å¤„ç†ç³»ç»Ÿ"""
    from utils.error_handler import ErrorHandler

    error_handler = ErrorHandler()

    # æµ‹è¯•é”™è¯¯å¤„ç†
    try:
        raise ValueError("æµ‹è¯•é”™è¯¯")
    except ValueError as e:
        error_handler.handle_error(e, "æµ‹è¯•ä¸Šä¸‹æ–‡")

    # æ£€æŸ¥é”™è¯¯æ˜¯å¦è¢«è®°å½•
    error_history = st.session_state.get('error_history', [])
    assert len(error_history) > 0

# Pytestæµ‹è¯•ç±»
class TestStreamlitApp:
    """Pytestæµ‹è¯•ç±»"""

    def setup_method(self):
        """æµ‹è¯•è®¾ç½®"""
        # æ¸…ç†session state
        for key in list(st.session_state.keys()):
            del st.session_state[key]

    def test_app_initialization(self):
        """æµ‹è¯•åº”ç”¨åˆå§‹åŒ–"""
        test_suite = StreamlitTestSuite()
        test_suite.test_main_app()

    def test_chat_functionality(self):
        """æµ‹è¯•èŠå¤©åŠŸèƒ½"""
        test_suite = StreamlitTestSuite()
        test_suite.test_chat_page()

    def test_analysis_functionality(self):
        """æµ‹è¯•åˆ†æåŠŸèƒ½"""
        test_suite = StreamlitTestSuite()
        test_suite.test_analysis_page()

    def test_settings_functionality(self):
        """æµ‹è¯•è®¾ç½®åŠŸèƒ½"""
        test_suite = StreamlitTestSuite()
        test_suite.test_settings_page()

    def test_session_management(self):
        """æµ‹è¯•ä¼šè¯ç®¡ç†"""
        test_suite = StreamlitTestSuite()
        test_suite.test_session_state_management()

    def test_error_handling_system(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†ç³»ç»Ÿ"""
        test_suite = StreamlitTestSuite()
        test_suite.test_error_handling()

if __name__ == "__main__":
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    print("ğŸ§ª å¼€å§‹Streamlitåº”ç”¨æµ‹è¯•")

    print("\nğŸ“± è¿è¡Œåº”ç”¨æµ‹è¯•...")
    test_suite = StreamlitTestSuite()
    test_suite.test_main_app()
    test_suite.test_chat_page()
    test_suite.test_analysis_page()
    test_suite.test_settings_page()

    print("\nğŸ”§ è¿è¡Œç»„ä»¶æµ‹è¯•...")
    run_component_tests()

    print("\nğŸ”— è¿è¡Œé›†æˆæµ‹è¯•...")
    run_integration_tests()

    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
```

### 2. æ€§èƒ½æµ‹è¯•è„šæœ¬ (tests/performance_tests.py)

```python
"""
æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•åº”ç”¨åœ¨å„ç§è´Ÿè½½æ¡ä»¶ä¸‹çš„æ€§èƒ½è¡¨ç°
"""

import time
import psutil
import pandas as pd
import streamlit as st
from concurrent.futures import ThreadPoolExecutor
import asyncio
from typing import Dict, List, Any
import matplotlib.pyplot as plt

class PerformanceTester:
    """æ€§èƒ½æµ‹è¯•å™¨"""

    def __init__(self):
        self.results = []
        self.baseline_metrics = {}

    def run_load_test(self, concurrent_users: int = 5, duration: int = 60):
        """è¿è¡Œè´Ÿè½½æµ‹è¯•"""
        print(f"å¼€å§‹è´Ÿè½½æµ‹è¯•: {concurrent_users} å¹¶å‘ç”¨æˆ·, {duration} ç§’")

        start_time = time.time()
        end_time = start_time + duration

        # è®°å½•åŸºçº¿æŒ‡æ ‡
        self.record_baseline_metrics()

        # å¹¶å‘ç”¨æˆ·æ¨¡æ‹Ÿ
        with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = []

            while time.time() < end_time:
                # æäº¤ç”¨æˆ·ä¼šè¯ä»»åŠ¡
                future = executor.submit(self.simulate_user_session)
                futures.append(future)

                time.sleep(1)  # æ¯ç§’ä¸€ä¸ªæ–°ç”¨æˆ·

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in futures:
                try:
                    result = future.result(timeout=30)
                    self.results.append(result)
                except Exception as e:
                    print(f"ç”¨æˆ·ä¼šè¯å¤±è´¥: {e}")

        # åˆ†æç»“æœ
        self.analyze_performance_results()

    def simulate_user_session(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿç”¨æˆ·ä¼šè¯"""
        session_start = time.time()

        try:
            # æ¨¡æ‹Ÿç”¨æˆ·æ“ä½œ
            operations = [
                self.simulate_page_load,
                self.simulate_chat_interaction,
                self.simulate_data_query,
                self.simulate_chart_rendering
            ]

            operation_results = []
            for operation in operations:
                op_start = time.time()
                operation()
                op_duration = time.time() - op_start
                operation_results.append({
                    'operation': operation.__name__,
                    'duration': op_duration
                })

            session_duration = time.time() - session_start

            return {
                'session_duration': session_duration,
                'operations': operation_results,
                'success': True,
                'timestamp': session_start
            }

        except Exception as e:
            return {
                'session_duration': time.time() - session_start,
                'operations': [],
                'success': False,
                'error': str(e),
                'timestamp': session_start
            }

    def simulate_page_load(self):
        """æ¨¡æ‹Ÿé¡µé¢åŠ è½½"""
        # æ¨¡æ‹Ÿé¡µé¢åˆå§‹åŒ–æ—¶é—´
        time.sleep(0.5)

    def simulate_chat_interaction(self):
        """æ¨¡æ‹ŸèŠå¤©äº¤äº’"""
        # æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥å’ŒAIå“åº”
        time.sleep(1.0)

    def simulate_data_query(self):
        """æ¨¡æ‹Ÿæ•°æ®æŸ¥è¯¢"""
        # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢æ—¶é—´
        time.sleep(2.0)

        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        data = pd.DataFrame({
            'id': range(1000),
            'value': range(1000, 2000),
            'category': ['A', 'B', 'C'] * 333 + ['A']
        })

        return data

    def simulate_chart_rendering(self):
        """æ¨¡æ‹Ÿå›¾è¡¨æ¸²æŸ“"""
        # æ¨¡æ‹Ÿå›¾è¡¨ç”Ÿæˆæ—¶é—´
        time.sleep(1.5)

    def record_baseline_metrics(self):
        """è®°å½•åŸºçº¿æ€§èƒ½æŒ‡æ ‡"""
        process = psutil.Process()

        self.baseline_metrics = {
            'cpu_percent': process.cpu_percent(),
            'memory_mb': process.memory_info().rss / 1024 / 1024,
            'threads': process.num_threads(),
            'timestamp': time.time()
        }

        print(f"åŸºçº¿æŒ‡æ ‡: CPU={self.baseline_metrics['cpu_percent']:.1f}%, "
              f"å†…å­˜={self.baseline_metrics['memory_mb']:.1f}MB")

    def analyze_performance_results(self):
        """åˆ†ææ€§èƒ½æµ‹è¯•ç»“æœ"""
        if not self.results:
            print("æ— æ€§èƒ½æµ‹è¯•ç»“æœ")
            return

        print("\nğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœåˆ†æ:")

        # æˆåŠŸç‡ç»Ÿè®¡
        successful_sessions = [r for r in self.results if r['success']]
        success_rate = len(successful_sessions) / len(self.results)
        print(f"ä¼šè¯æˆåŠŸç‡: {success_rate:.1%}")

        # å“åº”æ—¶é—´ç»Ÿè®¡
        session_durations = [r['session_duration'] for r in successful_sessions]
        if session_durations:
            avg_duration = sum(session_durations) / len(session_durations)
            max_duration = max(session_durations)
            min_duration = min(session_durations)

            print(f"å¹³å‡ä¼šè¯æ—¶é•¿: {avg_duration:.2f}s")
            print(f"æœ€é•¿ä¼šè¯æ—¶é•¿: {max_duration:.2f}s")
            print(f"æœ€çŸ­ä¼šè¯æ—¶é•¿: {min_duration:.2f}s")

        # æ“ä½œæ€§èƒ½ç»Ÿè®¡
        self.analyze_operation_performance(successful_sessions)

        # èµ„æºä½¿ç”¨ç»Ÿè®¡
        self.analyze_resource_usage()

    def analyze_operation_performance(self, sessions: List[Dict]):
        """åˆ†ææ“ä½œæ€§èƒ½"""
        operation_stats = {}

        for session in sessions:
            for op in session.get('operations', []):
                op_name = op['operation']
                op_duration = op['duration']

                if op_name not in operation_stats:
                    operation_stats[op_name] = []

                operation_stats[op_name].append(op_duration)

        print("\nğŸ”§ æ“ä½œæ€§èƒ½ç»Ÿè®¡:")
        for op_name, durations in operation_stats.items():
            avg_duration = sum(durations) / len(durations)
            max_duration = max(durations)
            print(f"{op_name}: å¹³å‡{avg_duration:.2f}s, æœ€å¤§{max_duration:.2f}s")

    def analyze_resource_usage(self):
        """åˆ†æèµ„æºä½¿ç”¨æƒ…å†µ"""
        try:
            process = psutil.Process()
            current_metrics = {
                'cpu_percent': process.cpu_percent(),
                'memory_mb': process.memory_info().rss / 1024 / 1024,
                'threads': process.num_threads()
            }

            print("\nğŸ’» èµ„æºä½¿ç”¨å¯¹æ¯”:")
            print(f"CPUä½¿ç”¨ç‡: {self.baseline_metrics['cpu_percent']:.1f}% â†’ {current_metrics['cpu_percent']:.1f}%")
            print(f"å†…å­˜ä½¿ç”¨: {self.baseline_metrics['memory_mb']:.1f}MB â†’ {current_metrics['memory_mb']:.1f}MB")
            print(f"çº¿ç¨‹æ•°: {self.baseline_metrics['threads']} â†’ {current_metrics['threads']}")

        except Exception as e:
            print(f"èµ„æºä½¿ç”¨åˆ†æé”™è¯¯: {e}")

    def run_stress_test(self, max_data_size: int = 100000):
        """è¿è¡Œå‹åŠ›æµ‹è¯•"""
        print(f"å¼€å§‹å‹åŠ›æµ‹è¯•: æœ€å¤§æ•°æ®é‡ {max_data_size} è¡Œ")

        data_sizes = [1000, 5000, 10000, 50000, max_data_size]
        stress_results = []

        for size in data_sizes:
            print(f"æµ‹è¯•æ•°æ®é‡: {size} è¡Œ")

            start_time = time.time()

            try:
                # åˆ›å»ºå¤§æ•°æ®é›†
                data = pd.DataFrame({
                    'id': range(size),
                    'value': range(size),
                    'category': ['A', 'B', 'C'] * (size // 3 + 1)
                })

                # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
                processed_data = data.groupby('category').sum()

                # æ¨¡æ‹Ÿå›¾è¡¨æ¸²æŸ“
                time.sleep(0.1)

                processing_time = time.time() - start_time
                memory_usage = psutil.Process().memory_info().rss / 1024 / 1024

                stress_results.append({
                    'data_size': size,
                    'processing_time': processing_time,
                    'memory_usage': memory_usage,
                    'success': True
                })

                print(f"âœ… æˆåŠŸå¤„ç† {size} è¡Œæ•°æ®ï¼Œè€—æ—¶ {processing_time:.2f}s")

            except Exception as e:
                stress_results.append({
                    'data_size': size,
                    'processing_time': 0,
                    'memory_usage': 0,
                    'success': False,
                    'error': str(e)
                })

                print(f"âŒ å¤„ç† {size} è¡Œæ•°æ®å¤±è´¥: {e}")

        self.analyze_stress_results(stress_results)

    def analyze_stress_results(self, results: List[Dict]):
        """åˆ†æå‹åŠ›æµ‹è¯•ç»“æœ"""
        print("\nğŸ“ˆ å‹åŠ›æµ‹è¯•ç»“æœ:")

        successful_results = [r for r in results if r['success']]

        if successful_results:
            print("æ•°æ®é‡ | å¤„ç†æ—¶é—´ | å†…å­˜ä½¿ç”¨")
            print("-" * 30)

            for result in successful_results:
                print(f"{result['data_size']:6d} | {result['processing_time']:8.2f}s | {result['memory_usage']:8.1f}MB")

            # å¯»æ‰¾æ€§èƒ½ç“¶é¢ˆ
            max_size = max(r['data_size'] for r in successful_results)
            print(f"\næœ€å¤§å¯å¤„ç†æ•°æ®é‡: {max_size:,} è¡Œ")

def run_memory_leak_test(duration: int = 300):
    """è¿è¡Œå†…å­˜æ³„æ¼æµ‹è¯•"""
    print(f"å¼€å§‹å†…å­˜æ³„æ¼æµ‹è¯•ï¼ŒæŒç»­ {duration} ç§’")

    memory_records = []
    start_time = time.time()

    while time.time() - start_time < duration:
        # æ¨¡æ‹Ÿåº”ç”¨æ“ä½œ
        simulate_app_operations()

        # è®°å½•å†…å­˜ä½¿ç”¨
        memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
        memory_records.append({
            'timestamp': time.time() - start_time,
            'memory_mb': memory_mb
        })

        time.sleep(10)  # æ¯10ç§’è®°å½•ä¸€æ¬¡

    # åˆ†æå†…å­˜è¶‹åŠ¿
    analyze_memory_trend(memory_records)

def simulate_app_operations():
    """æ¨¡æ‹Ÿåº”ç”¨æ“ä½œ"""
    # æ¨¡æ‹Ÿsession stateæ“ä½œ
    st.session_state['test_data'] = pd.DataFrame({
        'x': range(1000),
        'y': range(1000, 2000)
    })

    # æ¨¡æ‹Ÿç¼“å­˜æ“ä½œ
    time.sleep(0.1)

    # æ¸…ç†ä¸´æ—¶æ•°æ®
    if 'test_data' in st.session_state:
        del st.session_state['test_data']

def analyze_memory_trend(records: List[Dict]):
    """åˆ†æå†…å­˜è¶‹åŠ¿"""
    if len(records) < 2:
        print("å†…å­˜è®°å½•ä¸è¶³ï¼Œæ— æ³•åˆ†æè¶‹åŠ¿")
        return

    initial_memory = records[0]['memory_mb']
    final_memory = records[-1]['memory_mb']
    memory_growth = final_memory - initial_memory

    print(f"\nğŸ§  å†…å­˜æ³„æ¼æµ‹è¯•ç»“æœ:")
    print(f"åˆå§‹å†…å­˜: {initial_memory:.1f}MB")
    print(f"æœ€ç»ˆå†…å­˜: {final_memory:.1f}MB")
    print(f"å†…å­˜å¢é•¿: {memory_growth:.1f}MB")

    if memory_growth > 50:  # è¶…è¿‡50MBå¢é•¿è®¤ä¸ºå¯èƒ½æœ‰æ³„æ¼
        print("âš ï¸ å¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼")
    else:
        print("âœ… æœªæ£€æµ‹åˆ°æ˜æ˜¾å†…å­˜æ³„æ¼")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æ€§èƒ½æµ‹è¯•")

    # åˆ›å»ºæ€§èƒ½æµ‹è¯•å™¨
    tester = PerformanceTester()

    # è¿è¡Œä¸åŒç±»å‹çš„æµ‹è¯•
    print("\nğŸ“Š è´Ÿè½½æµ‹è¯•")
    tester.run_load_test(concurrent_users=3, duration=30)

    print("\nğŸ’ª å‹åŠ›æµ‹è¯•")
    tester.run_stress_test(max_data_size=50000)

    print("\nğŸ§  å†…å­˜æ³„æ¼æµ‹è¯•")
    run_memory_leak_test(duration=60)

    print("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆ")
```

### 3. éƒ¨ç½²é…ç½®æ–‡ä»¶

#### Dockeré…ç½® (Dockerfile)

```dockerfile
# ä½¿ç”¨Python 3.11ä½œä¸ºåŸºç¡€é•œåƒ
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONUNBUFFERED=1
ENV STREAMLIT_SERVER_PORT=8501
ENV STREAMLIT_SERVER_ADDRESS=0.0.0.0

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    software-properties-common \
    git \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶requirementsæ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p .streamlit logs

# å¤åˆ¶Streamlité…ç½®
COPY .streamlit/config.toml .streamlit/
COPY .streamlit/secrets.toml.example .streamlit/secrets.toml

# æš´éœ²ç«¯å£
EXPOSE 8501

# å¥åº·æ£€æŸ¥
HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health

# å¯åŠ¨å‘½ä»¤
CMD ["streamlit", "run", "main.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

#### Docker Composeé…ç½® (docker-compose.yml)

```yaml
version: '3.8'

services:
  streamlit-app:
    build: .
    ports:
      - "8501:8501"
    environment:
      - STREAMLIT_LOGGER_LEVEL=INFO
      - STREAMLIT_CLIENT_TOOLBAR_MODE=minimal
    volumes:
      - ./logs:/app/logs
      - ./.streamlit/secrets.toml:/app/.streamlit/secrets.toml
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # å¯é€‰ï¼šæ·»åŠ æ•°æ®åº“æœåŠ¡
  # postgres:
  #   image: postgres:15
  #   environment:
  #     POSTGRES_DB: streamlit_app
  #     POSTGRES_USER: streamlit
  #     POSTGRES_PASSWORD: password
  #   volumes:
  #     - postgres_data:/var/lib/postgresql/data
  #   ports:
  #     - "5432:5432"

  # å¯é€‰ï¼šæ·»åŠ Redisç¼“å­˜
  # redis:
  #   image: redis:7-alpine
  #   ports:
  #     - "6379:6379"
  #   volumes:
  #     - redis_data:/data

volumes:
  postgres_data:
  redis_data:
```

#### GitHub Actionsé…ç½® (.github/workflows/ci-cd.yml)

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11]

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov

    - name: Run linting
      run: |
        pip install flake8
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: Run tests
      run: |
        pytest tests/ -v --cov=. --cov-report=xml

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v3

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: Login to Docker Hub
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}

    - name: Build and push Docker image
      uses: docker/build-push-action@v4
      with:
        context: .
        push: true
        tags: |
          your-username/streamlit-app:latest
          your-username/streamlit-app:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - name: Deploy to production
      run: |
        echo "Deployment script would go here"
        # å®é™…éƒ¨ç½²å‘½ä»¤ï¼Œå¦‚ kubectl apply æˆ–äº‘å¹³å°éƒ¨ç½²å‘½ä»¤
```

### 4. ç›‘æ§å’Œæ—¥å¿—é…ç½® (utils/monitoring.py)

```python
"""
ç›‘æ§å’Œæ—¥å¿—é…ç½®
æä¾›åº”ç”¨ç›‘æ§ã€æ—¥å¿—è®°å½•å’Œå‘Šè­¦åŠŸèƒ½
"""

import logging
import json
import time
from datetime import datetime
from typing import Dict, Any, Optional
import streamlit as st
import os

class MonitoringSystem:
    """ç›‘æ§ç³»ç»Ÿ"""

    def __init__(self):
        self.setup_logging()
        self.setup_metrics_collection()

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        # åˆ›å»ºlogsç›®å½•
        os.makedirs('logs', exist_ok=True)

        # é…ç½®æ—¥å¿—æ ¼å¼
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('logs/app.log'),
                logging.StreamHandler()
            ]
        )

        self.logger = logging.getLogger('streamlit_monitoring')

    def setup_metrics_collection(self):
        """è®¾ç½®æŒ‡æ ‡æ”¶é›†"""
        if 'monitoring_metrics' not in st.session_state:
            st.session_state.monitoring_metrics = {
                'page_views': {},
                'user_actions': [],
                'errors': [],
                'performance': []
            }

    def log_page_view(self, page_name: str):
        """è®°å½•é¡µé¢è®¿é—®"""
        timestamp = time.time()

        # æ›´æ–°é¡µé¢è®¿é—®è®¡æ•°
        metrics = st.session_state.monitoring_metrics
        if page_name not in metrics['page_views']:
            metrics['page_views'][page_name] = 0
        metrics['page_views'][page_name] += 1

        # è®°å½•æ—¥å¿—
        self.logger.info(f"Page view: {page_name}")

    def log_user_action(self, action: str, details: Dict = None):
        """è®°å½•ç”¨æˆ·æ“ä½œ"""
        action_record = {
            'timestamp': time.time(),
            'action': action,
            'details': details or {},
            'session_id': st.session_state.get('session_id', 'unknown')
        }

        st.session_state.monitoring_metrics['user_actions'].append(action_record)

        # é™åˆ¶è®°å½•æ•°é‡
        if len(st.session_state.monitoring_metrics['user_actions']) > 1000:
            st.session_state.monitoring_metrics['user_actions'] = \
                st.session_state.monitoring_metrics['user_actions'][-1000:]

        self.logger.info(f"User action: {action}", extra={'details': details})

    def log_error(self, error: Exception, context: str = ""):
        """è®°å½•é”™è¯¯"""
        error_record = {
            'timestamp': time.time(),
            'error_type': type(error).__name__,
            'error_message': str(error),
            'context': context,
            'session_id': st.session_state.get('session_id', 'unknown')
        }

        st.session_state.monitoring_metrics['errors'].append(error_record)

        # é™åˆ¶è®°å½•æ•°é‡
        if len(st.session_state.monitoring_metrics['errors']) > 100:
            st.session_state.monitoring_metrics['errors'] = \
                st.session_state.monitoring_metrics['errors'][-100:]

        self.logger.error(f"Error in {context}: {error}", exc_info=True)

    def log_performance_metric(self, metric_name: str, value: float, unit: str = ""):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        metric_record = {
            'timestamp': time.time(),
            'metric_name': metric_name,
            'value': value,
            'unit': unit
        }

        st.session_state.monitoring_metrics['performance'].append(metric_record)

        # é™åˆ¶è®°å½•æ•°é‡
        if len(st.session_state.monitoring_metrics['performance']) > 500:
            st.session_state.monitoring_metrics['performance'] = \
                st.session_state.monitoring_metrics['performance'][-500:]

        self.logger.info(f"Performance metric: {metric_name} = {value} {unit}")

    def get_monitoring_dashboard(self) -> Dict[str, Any]:
        """è·å–ç›‘æ§ä»ªè¡¨æ¿æ•°æ®"""
        metrics = st.session_state.monitoring_metrics

        current_time = time.time()
        hour_ago = current_time - 3600

        # è®¡ç®—è¿‘ä¸€å°æ—¶çš„ç»Ÿè®¡æ•°æ®
        recent_actions = [
            a for a in metrics['user_actions']
            if a['timestamp'] > hour_ago
        ]

        recent_errors = [
            e for e in metrics['errors']
            if e['timestamp'] > hour_ago
        ]

        dashboard_data = {
            'total_page_views': sum(metrics['page_views'].values()),
            'recent_actions_count': len(recent_actions),
            'recent_errors_count': len(recent_errors),
            'most_visited_page': max(
                metrics['page_views'].items(),
                key=lambda x: x[1],
                default=('æ— ', 0)
            )[0],
            'error_rate': len(recent_errors) / max(len(recent_actions), 1),
            'uptime_hours': (current_time - st.session_state.get('app_start_time', current_time)) / 3600
        }

        return dashboard_data

    def export_logs(self, start_time: Optional[float] = None, end_time: Optional[float] = None) -> str:
        """å¯¼å‡ºæ—¥å¿—"""
        metrics = st.session_state.monitoring_metrics

        # è¿‡æ»¤æ—¶é—´èŒƒå›´
        filtered_data = {}

        if start_time and end_time:
            filtered_data['user_actions'] = [
                a for a in metrics['user_actions']
                if start_time <= a['timestamp'] <= end_time
            ]
            filtered_data['errors'] = [
                e for e in metrics['errors']
                if start_time <= e['timestamp'] <= end_time
            ]
            filtered_data['performance'] = [
                p for p in metrics['performance']
                if start_time <= p['timestamp'] <= end_time
            ]
        else:
            filtered_data = metrics

        return json.dumps(filtered_data, indent=2, ensure_ascii=False)

# å…¨å±€ç›‘æ§å®ä¾‹
monitoring_system = MonitoringSystem()

def monitor_function(func_name: str):
    """å‡½æ•°ç›‘æ§è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            start_time = time.time()

            try:
                result = func(*args, **kwargs)
                execution_time = time.time() - start_time

                monitoring_system.log_performance_metric(
                    f"{func_name}_execution_time",
                    execution_time,
                    "seconds"
                )

                return result

            except Exception as e:
                monitoring_system.log_error(e, func_name)
                raise

        return wrapper
    return decorator
```

### 5. éƒ¨ç½²æ£€æŸ¥æ¸…å• (deployment_checklist.md)

```markdown
# éƒ¨ç½²æ£€æŸ¥æ¸…å•

## ğŸ” éƒ¨ç½²å‰æ£€æŸ¥

### ä»£ç è´¨é‡
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [ ] ä»£ç è¦†ç›–ç‡ > 80%
- [ ] æ— å®‰å…¨æ¼æ´
- [ ] æ€§èƒ½æµ‹è¯•é€šè¿‡
- [ ] å†…å­˜æ³„æ¼æµ‹è¯•é€šè¿‡

### é…ç½®æ£€æŸ¥
- [ ] ç”Ÿäº§ç¯å¢ƒé…ç½®æ­£ç¡®
- [ ] æ•æ„Ÿä¿¡æ¯å·²ç§»å…¥ç¯å¢ƒå˜é‡
- [ ] æ•°æ®åº“è¿æ¥é…ç½®æ­£ç¡®
- [ ] ç¼“å­˜é…ç½®ä¼˜åŒ–
- [ ] æ—¥å¿—çº§åˆ«è®¾ç½®åˆé€‚

### å®‰å…¨æ£€æŸ¥
- [ ] ä¾èµ–åŒ…å®‰å…¨æ‰«æé€šè¿‡
- [ ] APIå¯†é’¥å®‰å…¨å­˜å‚¨
- [ ] ç”¨æˆ·è¾“å…¥éªŒè¯å®Œæ•´
- [ ] é”™è¯¯ä¿¡æ¯ä¸æ³„éœ²æ•æ„Ÿä¿¡æ¯
- [ ] HTTPSé…ç½®æ­£ç¡®

### æ€§èƒ½æ£€æŸ¥
- [ ] é¡µé¢åŠ è½½æ—¶é—´ < 3ç§’
- [ ] å¹¶å‘ç”¨æˆ·æ”¯æŒ > 50
- [ ] å†…å­˜ä½¿ç”¨ < 1GB
- [ ] CPUä½¿ç”¨ç‡ < 70%
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 80%

## ğŸš€ éƒ¨ç½²æ­¥éª¤

### 1. ç¯å¢ƒå‡†å¤‡
```bash
# åˆ›å»ºéƒ¨ç½²ç›®å½•
mkdir -p /opt/streamlit-app
cd /opt/streamlit-app

# å…‹éš†ä»£ç 
git clone <repository-url> .

# è®¾ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
vim .env
```

### 2. Dockeréƒ¨ç½²
```bash
# æ„å»ºé•œåƒ
docker build -t streamlit-app:latest .

# è¿è¡Œå®¹å™¨
docker-compose up -d

# æ£€æŸ¥çŠ¶æ€
docker-compose ps
docker-compose logs -f
```

### 3. å¥åº·æ£€æŸ¥
```bash
# æ£€æŸ¥åº”ç”¨çŠ¶æ€
curl http://localhost:8501/_stcore/health

# æ£€æŸ¥åŠŸèƒ½
curl http://localhost:8501/
```

### 4. ç›‘æ§è®¾ç½®
```bash
# é…ç½®æ—¥å¿—è½®è½¬
sudo logrotate -d /etc/logrotate.d/streamlit-app

# è®¾ç½®ç›‘æ§å‘Šè­¦
# é…ç½®Prometheus/Grafanaç­‰ç›‘æ§å·¥å…·
```

## ğŸ“Š éƒ¨ç½²åéªŒè¯

### åŠŸèƒ½éªŒè¯
- [ ] ä¸»é¡µæ­£å¸¸åŠ è½½
- [ ] èŠå¤©åŠŸèƒ½æ­£å¸¸
- [ ] æ•°æ®æŸ¥è¯¢æ­£å¸¸
- [ ] å›¾è¡¨æ¸²æŸ“æ­£å¸¸
- [ ] è®¾ç½®é¡µé¢æ­£å¸¸

### æ€§èƒ½éªŒè¯
- [ ] å“åº”æ—¶é—´æ­£å¸¸
- [ ] å†…å­˜ä½¿ç”¨æ­£å¸¸
- [ ] CPUä½¿ç”¨æ­£å¸¸
- [ ] å¹¶å‘å¤„ç†æ­£å¸¸

### ç›‘æ§éªŒè¯
- [ ] æ—¥å¿—æ­£å¸¸è®°å½•
- [ ] æŒ‡æ ‡æ­£å¸¸æ”¶é›†
- [ ] å‘Šè­¦æ­£å¸¸å·¥ä½œ
- [ ] å¥åº·æ£€æŸ¥æ­£å¸¸

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜
1. **åº”ç”¨æ— æ³•å¯åŠ¨**
   - æ£€æŸ¥ç«¯å£å ç”¨
   - æ£€æŸ¥ç¯å¢ƒå˜é‡
   - æŸ¥çœ‹é”™è¯¯æ—¥å¿—

2. **æ€§èƒ½é—®é¢˜**
   - æ£€æŸ¥èµ„æºä½¿ç”¨
   - ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢
   - è°ƒæ•´ç¼“å­˜é…ç½®

3. **åŠŸèƒ½å¼‚å¸¸**
   - æ£€æŸ¥ä¾èµ–ç‰ˆæœ¬
   - éªŒè¯é…ç½®æ–‡ä»¶
   - æŸ¥çœ‹åº”ç”¨æ—¥å¿—

### å›æ»šè®¡åˆ’
1. åœæ­¢å½“å‰ç‰ˆæœ¬
2. æ¢å¤ä¸Šä¸€ç‰ˆæœ¬é•œåƒ
3. éªŒè¯åŠŸèƒ½æ­£å¸¸
4. æ›´æ–°è´Ÿè½½å‡è¡¡å™¨
```

## éªŒæ”¶æ ‡å‡†

### æµ‹è¯•éªŒæ”¶
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
- [ ] é›†æˆæµ‹è¯•å…¨éƒ¨é€šè¿‡
- [ ] æ€§èƒ½æµ‹è¯•æ»¡è¶³è¦æ±‚
- [ ] ç”¨æˆ·éªŒæ”¶æµ‹è¯•é€šè¿‡
- [ ] å®‰å…¨æµ‹è¯•æ— é«˜å±æ¼æ´

### éƒ¨ç½²éªŒæ”¶
- [ ] ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æˆåŠŸ
- [ ] å¥åº·æ£€æŸ¥æ­£å¸¸
- [ ] ç›‘æ§ç³»ç»Ÿæ­£å¸¸
- [ ] æ—¥å¿—è®°å½•å®Œæ•´
- [ ] å¤‡ä»½æ¢å¤æµç¨‹æµ‹è¯•é€šè¿‡

### ç”¨æˆ·ä½“éªŒéªŒæ”¶
- [ ] åº”ç”¨åŠ è½½é€Ÿåº¦ < 3ç§’
- [ ] åŠŸèƒ½æ“ä½œæµç•…
- [ ] é”™è¯¯å¤„ç†å‹å¥½
- [ ] ç•Œé¢å“åº”åŠæ—¶
- [ ] æ•°æ®å±•ç¤ºå‡†ç¡®

### è¿ç»´éªŒæ”¶
- [ ] éƒ¨ç½²æ–‡æ¡£å®Œæ•´
- [ ] ç›‘æ§å‘Šè­¦é…ç½®å®Œæˆ
- [ ] æ—¥å¿—è½®è½¬æ­£å¸¸
- [ ] å¤‡ä»½ç­–ç•¥æ‰§è¡Œ
- [ ] æ•…éšœæ¢å¤æµç¨‹æµ‹è¯•

## åç»­ä¼˜åŒ–
å®Œæˆæ­¤ä»»åŠ¡åï¼Œé¡¹ç›®è¿›å…¥ç”Ÿäº§è¿è¡Œé˜¶æ®µï¼Œéœ€è¦æŒç»­ç›‘æ§ã€ä¼˜åŒ–å’Œç»´æŠ¤ã€‚